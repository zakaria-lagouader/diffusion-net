{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import potpourri3d as pp3d\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../../src/\"))  # add the path to the DiffusionNet src\n",
    "import diffusion_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Path to the pretrained model\n",
    "pretrain_path = \"data/saved_models/sal_model.pth\"\n",
    "\n",
    "# File paths\n",
    "root_dir = \"data/saliency_data/\"  # Change this to the actual root directory of your dataset\n",
    "file_name = \"bimba.ply\"  # Change this to the actual mesh file name\n",
    "label_file = \"bimba.val\"  # Change this to the actual label file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mesh and labels\n",
    "verts, faces = pp3d.read_mesh(os.path.join(root_dir, \"ply\", file_name))\n",
    "labels = np.loadtxt(os.path.join(root_dir, \"labels\", label_file)).astype(int) + 1  # shift -1 --> 0\n",
    "\n",
    "verts = torch.tensor(verts).float()\n",
    "faces = torch.tensor(faces)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Normalize positions\n",
    "verts = diffusion_net.geometry.normalize_positions(verts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_all_operators() processing 0 / 1 0.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZAKARIA\\AppData\\Local\\Temp\\ipykernel_6636\\4048726310.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  frames = torch.tensor(frames[0]).to(device)\n",
      "C:\\Users\\ZAKARIA\\AppData\\Local\\Temp\\ipykernel_6636\\4048726310.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mass = torch.tensor(mass[0]).to(device)\n",
      "C:\\Users\\ZAKARIA\\AppData\\Local\\Temp\\ipykernel_6636\\4048726310.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  L = torch.tensor(L[0]).to(device)\n",
      "C:\\Users\\ZAKARIA\\AppData\\Local\\Temp\\ipykernel_6636\\4048726310.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  evals = torch.tensor(evals[0]).to(device)\n",
      "C:\\Users\\ZAKARIA\\AppData\\Local\\Temp\\ipykernel_6636\\4048726310.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  evecs = torch.tensor(evecs[0]).to(device)\n",
      "C:\\Users\\ZAKARIA\\AppData\\Local\\Temp\\ipykernel_6636\\4048726310.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gradX = torch.tensor(gradX[0]).to(device)\n",
      "C:\\Users\\ZAKARIA\\AppData\\Local\\Temp\\ipykernel_6636\\4048726310.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gradY = torch.tensor(gradY[0]).to(device)\n"
     ]
    }
   ],
   "source": [
    "# Compute operators\n",
    "k_eig = 128  # Change this if needed\n",
    "verts_list, faces_list = [verts], [faces]\n",
    "frames, mass, L, evals, evecs, gradX, gradY = diffusion_net.geometry.get_all_operators(verts_list, faces_list, k_eig=k_eig)\n",
    "\n",
    "# Convert to tensors\n",
    "frames = torch.tensor(frames[0]).to(device)\n",
    "mass = torch.tensor(mass[0]).to(device)\n",
    "L = torch.tensor(L[0]).to(device)\n",
    "evals = torch.tensor(evals[0]).to(device)\n",
    "evecs = torch.tensor(evecs[0]).to(device)\n",
    "gradX = torch.tensor(gradX[0]).to(device)\n",
    "gradY = torch.tensor(gradY[0]).to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionNet(\n",
       "  (first_lin): Linear(in_features=16, out_features=128, bias=True)\n",
       "  (last_lin): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (block_0): DiffusionNetBlock(\n",
       "    (diffusion): LearnedTimeDiffusion()\n",
       "    (gradient_features): SpatialGradientFeatures(\n",
       "      (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (mlp): MiniMLP(\n",
       "      (miniMLP_mlp_layer_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (miniMLP_mlp_act_000): ReLU()\n",
       "      (miniMLP_mlp_layer_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "      (miniMLP_mlp_layer_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (miniMLP_mlp_act_001): ReLU()\n",
       "      (miniMLP_mlp_layer_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "      (miniMLP_mlp_layer_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (block_1): DiffusionNetBlock(\n",
       "    (diffusion): LearnedTimeDiffusion()\n",
       "    (gradient_features): SpatialGradientFeatures(\n",
       "      (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (mlp): MiniMLP(\n",
       "      (miniMLP_mlp_layer_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (miniMLP_mlp_act_000): ReLU()\n",
       "      (miniMLP_mlp_layer_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "      (miniMLP_mlp_layer_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (miniMLP_mlp_act_001): ReLU()\n",
       "      (miniMLP_mlp_layer_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "      (miniMLP_mlp_layer_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (block_2): DiffusionNetBlock(\n",
       "    (diffusion): LearnedTimeDiffusion()\n",
       "    (gradient_features): SpatialGradientFeatures(\n",
       "      (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (mlp): MiniMLP(\n",
       "      (miniMLP_mlp_layer_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (miniMLP_mlp_act_000): ReLU()\n",
       "      (miniMLP_mlp_layer_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "      (miniMLP_mlp_layer_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (miniMLP_mlp_act_001): ReLU()\n",
       "      (miniMLP_mlp_layer_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "      (miniMLP_mlp_layer_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (block_3): DiffusionNetBlock(\n",
       "    (diffusion): LearnedTimeDiffusion()\n",
       "    (gradient_features): SpatialGradientFeatures(\n",
       "      (A_re): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (A_im): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (mlp): MiniMLP(\n",
       "      (miniMLP_mlp_layer_000): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (miniMLP_mlp_act_000): ReLU()\n",
       "      (miniMLP_mlp_layer_dropout_001): Dropout(p=0.5, inplace=False)\n",
       "      (miniMLP_mlp_layer_001): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (miniMLP_mlp_act_001): ReLU()\n",
       "      (miniMLP_mlp_layer_dropout_002): Dropout(p=0.5, inplace=False)\n",
       "      (miniMLP_mlp_layer_002): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "input_features = \"hks\"  # Change this if using 'hks'\n",
    "C_in = {'xyz': 3, 'hks': 16}[input_features]\n",
    "n_class = 1\n",
    "\n",
    "model = diffusion_net.layers.DiffusionNet(\n",
    "    C_in=C_in,\n",
    "    C_out=n_class,\n",
    "    C_width=128,\n",
    "    N_block=4,\n",
    "    last_activation=torch.nn.functional.sigmoid,\n",
    "    outputs_at='vertices',\n",
    "    dropout=True\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(pretrain_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input features\n",
    "if input_features == 'xyz':\n",
    "    features = verts.to(device)\n",
    "elif input_features == 'hks':\n",
    "    features = diffusion_net.geometry.compute_hks_autoscale(evals, evecs, 16).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZAKARIA\\.conda\\envs\\diffusion_net\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    preds = model(features, mass, L=L, evals=evals, evecs=evecs, gradX=gradX, gradY=gradY)\n",
    "    preds = preds.squeeze().cpu().numpy()\n",
    "\n",
    "print(\"Predictions:\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
